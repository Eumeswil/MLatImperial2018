{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees & model selection\n",
    "\n",
    "![img](https://pbs.twimg.com/media/B13n2VVCIAA0hJS.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#update sklearn\n",
    "!pip install --upgrade scikit-learn > sklearn.log "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loading a toy dataset.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('data.npz')\n",
    "X,y = data[\"X\"],data[\"y\"]\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.5, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.scatter(X_train[:,0],X_train[:,1],c=y_train,cmap='nipy_spectral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision trees out of the box\n",
    "\n",
    "DecisionTreeClassifier has a number of parameters:\n",
    "* max_depth : a limit on tree depth (default : no limit)\n",
    "* min_samples_split : there should be at least this many samples to split further (default : 2)\n",
    "* min_samples_leaf : there should be at least this many samples on one side of a split to consider it valid (default : 1).\n",
    "* criterion : 'giny' or 'entropy' - split stuff over this parameter (default : giny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot decision surface\n",
    "\n",
    "This function takes your classifier and plots it's prediction at each point. Let's see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def plot_decision_surface(clf, X, y, plot_step = 0.2, cmap='nipy_spectral', figsize=(12,8)):\n",
    "    \"\"\" plot the decision boundary of clf on X and y, visualize training points\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    x0_grid, x1_grid = np.meshgrid(np.arange(X[:, 0].min() - 1, X[:, 0].max() + 1, plot_step),\n",
    "                         np.arange(X[:, 1].min() - 1, X[:, 1].max() + 1, plot_step))\n",
    "    y_pred_grid = clf.predict(np.stack([x0_grid.ravel(), x1_grid.ravel()],axis=1)).reshape(x1_grid.shape)\n",
    "    plt.contourf(x0_grid, x1_grid, y_pred_grid, cmap=cmap, alpha=0.5)  \n",
    "    y_pred = clf.predict(X)    \n",
    "    plt.scatter(*X[y_pred==y].T,c = y[y_pred==y],\n",
    "                marker='.',cmap=cmap,alpha=0.5,label='correct')\n",
    "    plt.scatter(*X[y_pred!=y].T,c = y[y_pred!=y],\n",
    "                marker='x',cmap=cmap,s=50,label='errors')\n",
    "    plt.legend(loc='best')\n",
    "    print(\"Accuracy = \",accuracy_score(y, y_pred))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_surface(tree,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test quality\n",
    "\n",
    "\n",
    "__Before you run it:__ guess what's gonna happen with test accuracy vs train accuracy judging by the train plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_surface(tree,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### We need a better tree!\n",
    "\n",
    "Try adjusting parameters of DecisionTreeClassifier to improve test accuracy.\n",
    " * Accuracy >= 0.72 - not bad for a start\n",
    " * Accuracy >= 0.75 - better, but not enough\n",
    " * Accuracy >= 0.77 - pretty good\n",
    " * Accuracy >= 0.78 - great! (probably the best result for a single tree)\n",
    " \n",
    "Feel free to modify the DecisionTreeClassifier above instead of re-writing everything.\n",
    "\n",
    "__Note:__ some of the parameters you can tune are under the \"Decision trees out of the box\" header."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### Ensembles\n",
    "\n",
    "Let's build our own decision tree bagging and see if it works. Implement __`BagOfTrees`__ class below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BagOfTrees:\n",
    "    \n",
    "    def __init__(self, n_estimators=10, **kwargs):\n",
    "        self.trees = []\n",
    "        for i in range(n_estimators):\n",
    "            self.trees.append(DecisionTreeClassifier(**kwargs))\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # Fit each of the trees on a random subset of X and y.\n",
    "        # hint: you can select random subsample of data liek this:\n",
    "        # >>> ix = np.random.randint(0, len(X), len(X))\n",
    "        # >>> X_sample, y_sample = X[ix], y[ix]\n",
    "\n",
    "        <YOUR CODE>\n",
    "        \n",
    "    def predict(self, X):\n",
    "        trees = self.trees\n",
    "        \n",
    "        # Compute predictions of each tree and aggregate them into the ensemble prediction\n",
    "        # Note: you can use tree.predict(X) or tree.predict_proba(X) to get individual predicitons\n",
    "        \n",
    "        return <YOURCODE - np.array of prediction indices>\n",
    "    \n",
    "# once you thing you're done, see if your code passes asserts below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = BagOfTrees(n_estimators=100, min_samples_leaf=5)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(map(str, model.trees[:2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test[::100])\n",
    "print(\"predictions:\", pred)\n",
    "assert isinstance(pred, np.ndarray), \"prediction must be a numpy array\"\n",
    "assert str(pred.dtype).startswith('int'), \"prediction dtype must be integer (int32/int64)\"\n",
    "assert pred.ndim == 1, \"prediction must be a vector (1-dimensional)\"\n",
    "assert len(pred) == len(X_test[::100]), \"must predict exactly one answer for each input (expected length %i, got %i)\" % (len(X_test[::100]), len(pred))\n",
    "assert any(model.trees[0].predict(X_train) != model.trees[1].predict(X_train)), \"All trees are the same. Did you forget to train each tree on a random part of data?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tree in enumerate(model.trees[:5]):\n",
    "    print(\"tree %i individual accuracy = %.5f\"%(i+1, accuracy_score(y_test,tree.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ensemble accuracy:\", accuracy_score(model.predict(X_test), y_test)) # should be >= 0.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_surface(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "### Using  existing ensembles : Random Forest\n",
    "\n",
    "RandomForest combines bagging and random subspaces: each tree uses a fraction of training samples and while split in that tree is chosen among a subset of features. This leads to a slightly better performance.\n",
    "\n",
    "__Note:__ try re-running your code a few times and see what happens to accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Task: create and fit a random forest with 100 estimators and at least 5 samples per leaf\n",
    "\n",
    "model = <YOUR CODE>\n",
    "\n",
    "<YOUR CODE>\n",
    "\n",
    "plot_decision_surface(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(model.predict(X_test), y_test)\n",
    "assert acc >= 0.792, \"acc is below 0.792. Try changing random forest hyperparameters.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using existing ensembles : Gradient Boosting\n",
    "\n",
    "__Note:__ if you don't have xgboost, use from sklearn.ensemble import GradientBoostingClassifier as XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from IPython.display import clear_output\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_estimators in range(1,10):\n",
    "    model = XGBClassifier(max_depth=3, learning_rate=0.5, n_estimators=n_estimators)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"n_estimators = \", n_estimators)\n",
    "    plot_decision_surface(model, X_test, y_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search\n",
    "\n",
    "__Bonus Quest:__ Find optimal parameters for GradientBoostingClassifier using grid search.\n",
    "\n",
    "This time please use a special validation set (i.e. don't make decisions based on X_test, y_test).\n",
    "\n",
    "You can implement a loop that searches over max_depth and learning_rate for a __fixed n_estmators=100__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "< YOUR CODE HERE >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = <your_code>\n",
    "plot_decision_surface(final_model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "### Automatic ML: model selection\n",
    "\n",
    "While grid search is reasonably good for parameter optimization, it oftentimes spends a lot of times exploring hopeless regions. There are other approaches to finding optimal model that can result in drastically smaller cpu time.\n",
    "\n",
    "The first approach is __bayesian optimization__, whos main idea is to model probability density function of a score (e.g. accuracy) at every point and explore points that are most likely to give optimal solution. The \"wilingness to try this point\" is called the acquisition function.\n",
    "\n",
    "Here's an example:\n",
    "![gp](https://cloud.google.com/blog/big-data/2017/08/images/150162099779222/hyperparameter-31-c.png)\n",
    "\n",
    "\n",
    "The most popular bayesian optimization methods are __gaussian process optimization(GP)__ and __tree-structured parzen estimators (TPE)__, differning mainly in the way they estimate the distributions. \n",
    "\n",
    "This time we're gonna see TPE in action using the [modelgym](https://github.com/yandexdataschool/modelgym) package.\n",
    "\n",
    "_warning: the package is still in early development, some things may suddenly break down_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install https://github.com/yandexdataschool/modelgym/archive/master.zip > modelgym.log\n",
    "!pip install lightgbm > lightgbm.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from modelgym.models import CtBClassifier # CatBoost gradient boosting\n",
    "from modelgym.utils import XYCDataset, ModelSpace\n",
    "from modelgym.metrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from modelgym.trainers import TpeTrainer\n",
    "\n",
    "trainer = TpeTrainer([ModelSpace(CtBClassifier, {'iterations':25})]) #you can add more models here...\n",
    "\n",
    "trainer.crossval_optimize_params(Accuracy(), XYCDataset(X_train, y_train), cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.get_best_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "An alternative approach here is __stochastic optimization__. If bayesian optimization is like a scalpel that cuts precisely where it should, stochastic optimization is a shotgun that shoots a bunch of pellets and sees which of them are most successful.\n",
    "\n",
    "We're gonna see this in action with the help of [tpot](https://github.com/EpistasisLab/tpot/) - a library for hyperparameter optimization via genetic programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install tpot > tpot.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "trainer = TPOTClassifier(population_size=50, generations=10, # genetic algorithm params\n",
    "                         cv=3,                               # 3-fold cross-validation\n",
    "                         n_jobs=4,                           # parallel processes\n",
    "                         max_eval_time_mins = 0.5            # model should train in under 30 seconds\n",
    "                         verbosity=2,\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = trainer.fitted_pipeline_\n",
    "print(\"TPOT test accuracy =\", accuracy_score(y_test, best_model.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
